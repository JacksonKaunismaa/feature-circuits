{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/can/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from nnsight import LanguageModel\n",
    "from dictionary_learning import ActivationBuffer\n",
    "from dictionary_learning.interp import examine_dimension\n",
    "from dictionary_learning.utils import zst_to_generator\n",
    "from loading_utils import load_submodules_and_dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "model = LanguageModel('EleutherAI/pythia-70m-deduped', device_map=device)\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPTNeoXTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 35\u001b[0m\n\u001b[1;32m     19\u001b[0m buffer \u001b[38;5;241m=\u001b[39m ActivationBuffer(\n\u001b[1;32m     20\u001b[0m     data,\n\u001b[1;32m     21\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     n_ctxs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m out \u001b[38;5;241m=\u001b[39m examine_dimension(\n\u001b[1;32m     29\u001b[0m     model,\n\u001b[1;32m     30\u001b[0m     submodule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     dim_idx\u001b[38;5;241m=\u001b[39mfeat_idx,\n\u001b[1;32m     34\u001b[0m )\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtop_tokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     36\u001b[0m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_contexts\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "component_idx = 1\n",
    "feat_idx = 19812\n",
    "\n",
    "submodules, submodule_names, dictionaries = load_submodules_and_dictionaries(\n",
    "        model,\n",
    "        use_attn=True,\n",
    "        use_mlp=True,\n",
    "        use_resid=True,\n",
    "        dict_path=\"/share/projects/dictionary_circuits/autoencoders/pythia-70m-deduped/\",\n",
    "        dict_size=512*64,\n",
    "        device='cuda:0',\n",
    ")\n",
    "\n",
    "submodule = submodules[component_idx]\n",
    "dictionary = dictionaries[submodule]\n",
    "\n",
    "# interpret some features\n",
    "data = zst_to_generator('/share/data/datasets/pile/the-eye.eu/public/AI/pile/train/00.jsonl.zst')\n",
    "buffer = ActivationBuffer(\n",
    "    data,\n",
    "    model,\n",
    "    [submodule],\n",
    "    out_feats=512,\n",
    "    in_batch_size=128,\n",
    "    n_ctxs=512,\n",
    ")\n",
    "\n",
    "out = examine_dimension(\n",
    "    model,\n",
    "    submodule,\n",
    "    buffer,\n",
    "    dictionary,\n",
    "    dim_idx=feat_idx,\n",
    ")\n",
    "print(out['top_tokens'])\n",
    "out['top_contexts']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
