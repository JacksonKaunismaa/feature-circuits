{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/can/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import zstandard as zstd\n",
    "import io\n",
    "import json\n",
    "import torch as t\n",
    "import einops\n",
    "from nnsight import LanguageModel\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from loading_utils import load_submodule_and_dictionary, DictionaryCfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = LanguageModel('EleutherAI/pythia-70m-deduped', device_map='cuda:0')\n",
    "\n",
    "dictionary_dir = \"/share/projects/dictionary_circuits/autoencoders/pythia-70m-deduped\"\n",
    "dictionary_size = 32768\n",
    "submodule, dictionary = load_submodule_and_dictionary(\n",
    "    model, \n",
    "    submod_name='model.gpt_neox.layers.5.mlp.dense_4h_to_h',\n",
    "    dict_cfg=DictionaryCfg(dictionary_dir, dictionary_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data as a generator\n",
    "data_path = '/share/data/datasets/pile/the-eye.eu/public/AI/pile/train/00.jsonl.zst'\n",
    "compressed_file = open(data_path, 'rb')\n",
    "dctx = zstd.ZstdDecompressor()\n",
    "reader = dctx.stream_reader(compressed_file)\n",
    "text_stream = io.TextIOWrapper(reader, encoding='utf-8')\n",
    "\n",
    "def generator():\n",
    "    for line in text_stream:\n",
    "        yield json.loads(line)['text']\n",
    "data = generator()\n",
    "\n",
    "def text_batch(batch_size):\n",
    "        \"\"\"\n",
    "        Return a list of text\n",
    "        \"\"\"\n",
    "        return [\n",
    "            next(data) for _ in range(batch_size)\n",
    "        ]\n",
    "\n",
    "def tokenized_batch(model, ctx_len, batch_size):\n",
    "        \"\"\"\n",
    "        Return a batch of tokenized inputs.\n",
    "        \"\"\"\n",
    "        texts = text_batch(batch_size=batch_size)\n",
    "        return model.tokenizer(\n",
    "            texts,\n",
    "            return_tensors='pt',\n",
    "            max_length=ctx_len,\n",
    "            padding=True,\n",
    "            truncation=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of prompt_tokid: torch.Size([1, 99])\n",
      "prompt:\n",
      "It is done, and submitted. You can play “Survival of the Tastiest” on Android, and on the web. Playing on the web works, but you have to simulate multi-touch for table moving and that can be a bit confusing.\n",
      "\n",
      "There’s a lot I’d like to talk about. I’ll go through every topic, insted of making the typical what went right/wrong list.\n",
      "\n",
      "Concept\n",
      "\n",
      "Working over the theme was probably\n"
     ]
    }
   ],
   "source": [
    "len_tokenized_prompt = 100\n",
    "\n",
    "prompt_str = next(data)\n",
    "prompt_tokid = model.tokenizer.encode(prompt_str, return_tensors='pt')[:, :len_tokenized_prompt]\n",
    "\n",
    "prompt_prefix = prompt_tokid[:, :-1]\n",
    "prompt_final_tok = prompt_tokid[:, -1:]\n",
    "\n",
    "print(f'shape of prompt_tokid: {prompt_prefix.shape}')\n",
    "print(f'prompt:\\n{model.tokenizer.decode(prompt_tokid[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metric as final token logit\n",
    "def metric_fn(model):\n",
    "    logits = model.embed_out.output\n",
    "    batch_size = logits.shape[0]\n",
    "    return logits[t.arange(batch_size), -1, prompt_final_tok]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/can/.local/lib/python3.8/site-packages/nnsight/util.py:48: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
      "  object = getattr(object, atom)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Accessing Proxy value before it's been set.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     metric_clean \u001b[38;5;241m=\u001b[39m metric_fn(model)\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m     14\u001b[0m metric_clean\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_act.shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_act\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_act.grad.shape:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(f_grad\u001b[38;5;241m.\u001b[39mvalue)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nnsight/intervention.py:128\u001b[0m, in \u001b[0;36mInterventionProxy.value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Property to return the value of this proxy's node.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    Any: The stored value of the proxy, populated during execution of the model.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39m_empty:\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing Proxy value before it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms been set.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mvalue\n",
      "\u001b[0;31mValueError\u001b[0m: Accessing Proxy value before it's been set."
     ]
    }
   ],
   "source": [
    "# Cache the gradients of the correct logit w.r.t dictionary features \n",
    "\n",
    "with model.invoke(prompt_prefix, fwd_args={'inference' : False}) as invoker:\n",
    "    # Cache feature activations\n",
    "    x = submodule.output\n",
    "    f_act = dictionary.encode(x)\n",
    "    f_grad = f_act.grad.save()\n",
    "\n",
    "    # Cache feature gradients\n",
    "    x_hat = dictionary.decode(f_act)\n",
    "    residual = (x - x_hat).detach()\n",
    "    submodule.output = x_hat + residual\n",
    "    metric_clean = metric_fn(model).save()\n",
    "metric_clean.value.sum().backward()\n",
    "\n",
    "print(f'feature_act.shape: {f_act.value}')\n",
    "print(f'feature_act.grad.shape:')\n",
    "print(f_grad.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error reproduction\n",
    "\n",
    "# def metric_fn(model):\n",
    "#     logits = model.embed_out.output\n",
    "#     batch_size = logits.shape[0]\n",
    "#     return logits[t.arange(batch_size), -1, prompt_final_tok]\n",
    "\n",
    "# with model.invoke('Hello World', fwd_args={'inference' : False}) as invoker:\n",
    "#     x = submodule.output\n",
    "#     x.retain_grad()\n",
    "#     x_clean = x.save()\n",
    "#     metric_clean = metric_fn(model).save()\n",
    "# metric_clean.value.sum().backward()\n",
    "\n",
    "# print(f'metric_clean: {metric_clean.value}')\n",
    "# print(f'x_clean: {x_clean.value}')\n",
    "# print(f'x_clean.grad:')\n",
    "# print(x_clean.grad.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_batch_size = 64\n",
    "ctx_len = 64\n",
    "prompt_batch_tokid = tokenized_batch(model, ctx_len, text_batch_size)['input_ids']\n",
    "\n",
    "prompt_batch_prefix = prompt_batch_tokid[:, :-1]\n",
    "prompt_batch_final_tok = prompt_batch_tokid[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metric as final token logit\n",
    "def metric_final_token_logit_batch(model):\n",
    "    logits = model.embed_out.output\n",
    "    batch_size = logits.shape[0]\n",
    "    return logits[t.arange(batch_size), -1, prompt_batch_final_tok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPTNeoXTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 63, 32768])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with model.invoke(prompt_batch_prefix) as invoker:\n",
    "    mlp_act = submodule.output\n",
    "    f_act = dictionary.encode(mlp_act).save()\n",
    "\n",
    "f_act.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4032, 32768)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_vecs = einops.rearrange(f_act.value, 'b p d -> (b p) d').to('cpu').detach().numpy()\n",
    "feat_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Normalize feature vectors\n",
    "norm = normalize(feat_vecs, axis=1, norm='l2')\n",
    "\n",
    "# Similarity matrix\n",
    "sim = cosine_similarity(norm)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = einops.rearrange(prompt_batch_tokid, 'b p -> (b p)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized prompt:  to\n",
      "\t\n",
      "\n",
      "\t to\n",
      "\t13\n",
      "\t some\n",
      "\t worst\n",
      "\t  \n",
      "\t trans\n",
      "\t got\n",
      "\tTi\n",
      "\t to\n",
      "\n",
      "\n",
      "tokenized prompt: col\n",
      "\t but\n",
      "\t b\n",
      "\tWe\n",
      "\t is\n",
      "\t,\n",
      "\t?\n",
      "\t this\n",
      "\tcol\n",
      "\t-\n",
      "\t.\n",
      "\n",
      "\n",
      "tokenized prompt: Ad\n",
      "\t every\n",
      "\t about\n",
      "\t school\n",
      "\tvent\n",
      "\t herein\n",
      "\tjamin\n",
      "\touts\n",
      "\tbalanced\n",
      "\tAd\n",
      "\t,\n",
      "\n",
      "\n",
      "tokenized prompt:  tissue\n",
      "\t ultrasound\n",
      "\t perform\n",
      "\t sad\n",
      "\tos\n",
      "\t bone\n",
      "\t\n",
      "\n",
      "\t tissue\n",
      "\t thought\n",
      "\t never\n",
      "\t K\n",
      "\n",
      "\n",
      "tokenized prompt:  are\n",
      "\t for\n",
      "\t industrial\n",
      "\t\n",
      "\n",
      "\t environment\n",
      "\t.\n",
      "\t alcohol\n",
      "\t are\n",
      "\tent\n",
      "\t EPS\n",
      "\tPs\n",
      "\n",
      "\n",
      "tokenized prompt:  post\n",
      "\t…\n",
      "\t will\n",
      "\t recording\n",
      "\tTi\n",
      "\tEx\n",
      "\t.\n",
      "\t show\n",
      "\t\n",
      "\n",
      "\t post\n",
      "\t some\n",
      "\n",
      "\n",
      "tokenized prompt: .\n",
      "\t augmented\n",
      "\t the\n",
      "\t database\n",
      "\t script\n",
      "\t combined\n",
      "\t a\n",
      "\t saving\n",
      "\t reality\n",
      "\t a\n",
      "\t.\n",
      "\n",
      "\n",
      "tokenized prompt:  the\n",
      "\t teaching\n",
      "\t happening\n",
      "\t and\n",
      "\t meeting\n",
      "\t work\n",
      "\t the\n",
      "\t like\n",
      "\tfact\n",
      "\tThis\n",
      "\t The\n",
      "\n",
      "\n",
      "tokenized prompt: ,\n",
      "\t hand\n",
      "\t,\n",
      "\t one\n",
      "\t Democratic\n",
      "\t refractory\n",
      "\t patients\n",
      "\t,\n",
      "\tUSE\n",
      "\t could\n",
      "\t the\n",
      "\n",
      "\n",
      "tokenized prompt: pires\n",
      "\t patients\n",
      "\t trio\n",
      "\t tem\n",
      "\t a\n",
      "\t and\n",
      "\t —\n",
      "\tpires\n",
      "\tES\n",
      "\t plotting\n",
      "\t am\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "looking_at = np.random.choice(len(prompt_list), 10)\n",
    "\n",
    "for i in looking_at:\n",
    "    print(f'tokenized prompt: {model.tokenizer.decode(prompt_list[i])}')\n",
    "    indices = np.argpartition(sim[i], -k)[-k:]\n",
    "    for index in indices:\n",
    "        print(f'\\t{model.tokenizer.decode(prompt_list[index])}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral clustering w/ cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 47 47 ... 11 39 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/can/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# Degree matrix\n",
    "deg = np.diag(np.sum(sim, axis=1))\n",
    "\n",
    "# Graph Laplacian\n",
    "lap = deg - sim\n",
    "\n",
    "# Eigen decomposition  \n",
    "w, v = np.linalg.eigh(lap)\n",
    "\n",
    "# Extract second smallest eigenvector    \n",
    "eigenvector = v[:, 1]  \n",
    "\n",
    "# kMeans clustering\n",
    "kmeans = KMeans(n_clusters=50, random_state=0)\n",
    "kmeans.fit(eigenvector.reshape(-1,1)) \n",
    "\n",
    "print(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       "       dtype=int32),\n",
       " array([  69,   11,    2,  705,    1,    1,   44,    1,   47,    1,    2,\n",
       "        1244,    1,   29,    1,    1,    2,   15,  230,   35,   32,    1,\n",
       "           1,  114,   20,    1,    1,   28,   20,    1,   29,   93,  478,\n",
       "           4,   47,   78,   35,  153,    1,  142,    1,    1,   35,   61,\n",
       "           1,    3,   33,  159,    7,   10]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(kmeans.labels_, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(kmeans.labels_, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<\n",
      " our\n",
      "\n",
      "\n",
      " of\n",
      " and\n",
      " was\n",
      "\n",
      "\n",
      "}\n",
      "\n",
      "\n",
      " list\n",
      " While\n",
      " de\n",
      "ú\n",
      "ación\n",
      " the\n",
      " movement\n",
      " role\n",
      "el\n",
      " comfortably\n",
      " body\n",
      " in\n",
      ".\n",
      ",\n",
      " standard\n",
      " Here\n",
      " properties\n",
      " pain\n",
      "\n",
      "\n",
      ".\n",
      " learned\n",
      ",\n",
      " always\n",
      " python\n",
      " environment\n",
      " are\n",
      " pregnancy\n",
      ")\n",
      " of\n",
      " phosphate\n",
      " of\n",
      " according\n",
      "prints\n",
      "r\n",
      " and\n",
      " defending\n",
      " new\n",
      "(\n",
      ",\n",
      "ter\n",
      " map\n",
      " benefit\n",
      " formed\n",
      " Indian\n",
      " Brothers\n",
      "\n",
      "\n",
      "426\n",
      " probably\n",
      " and\n",
      " in\n",
      "Today\n",
      " could\n",
      " vol\n",
      " the\n",
      "...\n",
      "aks\n",
      "ord\n",
      "Rog\n",
      "\n",
      "\n",
      " controllers\n",
      " P\n",
      " em\n",
      "ro\n",
      " read\n",
      " St\n",
      " how\n",
      " I\n",
      " news\n",
      "'s\n"
     ]
    }
   ],
   "source": [
    "cluster_idx = 35\n",
    "\n",
    "for idx, lbl in enumerate(kmeans.labels_):\n",
    "    if lbl == cluster_idx:\n",
    "        print(model.tokenizer.decode(prompt_list[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
