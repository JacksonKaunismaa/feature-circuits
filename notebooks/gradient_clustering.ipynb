{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/can/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import zstandard as zstd\n",
    "import io\n",
    "import json\n",
    "from nnsight import LanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = LanguageModel('EleutherAI/pythia-70m-deduped', device_map='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data as a generator\n",
    "data_path = '/share/data/datasets/pile/the-eye.eu/public/AI/pile/train/00.jsonl.zst'\n",
    "compressed_file = open(data_path, 'rb')\n",
    "dctx = zstd.ZstdDecompressor()\n",
    "reader = dctx.stream_reader(compressed_file)\n",
    "text_stream = io.TextIOWrapper(reader, encoding='utf-8')\n",
    "\n",
    "def generator():\n",
    "    for line in text_stream:\n",
    "        yield json.loads(line)['text']\n",
    "data = generator()\n",
    "\n",
    "def text_batch(batch_size):\n",
    "        \"\"\"\n",
    "        Return a list of text\n",
    "        \"\"\"\n",
    "        return [\n",
    "            next(data) for _ in range(batch_size)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of prompt_tokid: torch.Size([1, 159])\n",
      "prompt:\n",
      "Running\n",
      "\n",
      "Stat\n",
      "\n",
      "Dinner with people is always better than eating alone, especially when the food is good. Good food tastes even better when enjoyed with people. Tonight Amy came over to try my second attempt at the Brussels Sprouts Veggie Soup to which I have made some changes (see recipe below in previous post) for a better result, I believe.\n",
      "\n",
      "We were at the store earlier and saw some nice looking haricot verts and heirloom tomatoes, so we decide to assemble a simple salad from those. Of course while I’m at the market, I can’t not get some five peppercorn salami. Our simple dinner of soup, salami, bread, cheese, salad, and wine was on the table in 15 minutes.\n"
     ]
    }
   ],
   "source": [
    "len_tokenized_prompt = 50\n",
    "\n",
    "prompt_str = next(data)\n",
    "prompt_tokid = model.tokenizer.encode(prompt_str, return_tensors='pt')[:len_tokenized_prompt]\n",
    "\n",
    "print(f'shape of prompt_tokid: {prompt_tokid.shape}')\n",
    "print(f'prompt:\\n{model.tokenizer.decode(prompt_tokid[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache the gradients of the correct logit w.r.t dictionary features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
